{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1432a56-7160-4f5e-b676-a1dc42453c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torch\n",
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83d50ab8-0695-4de5-9107-47b32f1d684b",
   "metadata": {},
   "outputs": [],
   "source": [
    "alldata = pd.read_csv('vehicle.csv', header=0, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd218efc-3a2d-45a6-803c-fcd791b002e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(data):\n",
    "    split_point = int(0.8 * len(data))\n",
    "    data_train = data[:split_point]\n",
    "    data_test = data[split_point:]\n",
    "    print(\"Length of whole dataset: \" + str(len(data)))\n",
    "    print(\"Length of train dataset: \" + str(len(data_train)))\n",
    "    print(\"Length of test dataset: \" + str(len(data_test)))\n",
    "    return data_train, data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a295333-9554-471a-bee3-62718a4ea73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(y_expected, y_predicted):\n",
    "    precision, recall, fscore, support = precision_recall_fscore_support(y_expected, y_predicted, average=\"weighted\")\n",
    "    accuracy = accuracy_score(y_expected, y_predicted)\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F-score: {fscore}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4278c193-ae38-4b0b-90a9-5d3ad9157d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of whole dataset: 846\n",
      "Length of train dataset: 676\n",
      "Length of test dataset: 170\n"
     ]
    }
   ],
   "source": [
    "data_train, data_test = split(alldata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16922d96-8ae0-4435-b204-730d6f855a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.DataFrame(data_train['Class'])\n",
    "x_train = pd.DataFrame(data_train.iloc[:,:-1])\n",
    "scaler = StandardScaler().fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "\n",
    "x_test = pd.DataFrame(data_test.iloc[:,:-1])\n",
    "x_test = scaler.transform(x_test)\n",
    "y_expected = pd.DataFrame(data_test['Class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3879a5f3-f53b-4401-83c2-60c0d08099af",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9765541f-23f3-4be0-b870-f6274d472da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8352941176470589\n",
      "Precision: 0.8322901539864602\n",
      "Recall: 0.8352941176470589\n",
      "F-score: 0.8315815818145278\n"
     ]
    }
   ],
   "source": [
    "model_logreg = LogisticRegression(solver = \"liblinear\", max_iter=1000,  penalty = 'l1') \n",
    "model_logreg.fit(x_train, y_train.values.ravel())\n",
    "\n",
    "y_predicted_logreg = model_logreg.predict(x_test) \n",
    "\n",
    "evaluation(y_expected, y_predicted_logreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829f5b59-ee63-4eac-97ab-b873d6b7ee22",
   "metadata": {},
   "source": [
    "## C-Support Vector Classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10b52c93-181b-47a1-a2b2-0ba1f298c392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8176470588235294\n",
      "Precision: 0.8117886456908344\n",
      "Recall: 0.8176470588235294\n",
      "F-score: 0.813678535845978\n"
     ]
    }
   ],
   "source": [
    "model_svc = SVC(gamma='auto').fit(x_train, y_train.values.ravel())\n",
    "y_predicted_v3 = model_svc.predict(x_test)\n",
    "\n",
    "evaluation(y_expected, y_predicted_v3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e56cba-b974-43e2-b9af-c222f4b65434",
   "metadata": {},
   "source": [
    "## Pytorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bb8e066-648c-4c90-a190-5e9d6d13a0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Adrian\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'van': 0, 'saab': 1, 'bus': 2, 'opel': 3}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_numpy = alldata.drop(\"Class\", axis=1).values\n",
    "X_numpy = scaler.transform(X_numpy)\n",
    "target_map = {\n",
    "    val: index for index, val in enumerate(alldata.Class.unique())\n",
    "}\n",
    "y_numpy = alldata.Class.map(target_map).values\n",
    "X = torch.tensor(X_numpy, dtype=torch.float32)\n",
    "y = torch.tensor(y_numpy)\n",
    "\n",
    "target_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4be2a57-a125-4d41-aada-b0c20560bf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(vector):\n",
    "    n_classes = len(vector.unique())\n",
    "    one_hot = torch.zeros((vector.shape[0], n_classes))\\\n",
    "        .type(torch.LongTensor)\n",
    "    return one_hot\\\n",
    "        .scatter(1, vector.type(torch.LongTensor).unsqueeze(1), 1)\n",
    "\n",
    "y_one_hot = one_hot_encode(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d0dcc9a-d06d-48a3-a418-65f386e58977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "846\n"
     ]
    }
   ],
   "source": [
    "random_indices = torch.randperm(X.shape[0])\n",
    "print(X.shape[0])\n",
    "n_train = int(0.8 * X.shape[0])\n",
    "X_train = X[random_indices[:n_train]]\n",
    "y_train = y[random_indices[:n_train]]\n",
    "y_train_one_hot = y_one_hot[random_indices[:n_train]]\n",
    "\n",
    "X_test = X[random_indices[n_train:]]\n",
    "y_test = y[random_indices[n_train:]]\n",
    "y_test_one_hot = y_one_hot[random_indices[n_train:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b449f03-a2a5-405c-9e99-bf090cc8da7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(18, 4)\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "loss_function = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c396fb7-e291-4e5b-8946-c936b44bd156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at iteration 1: 1.4181666374206543\n",
      "Loss at iteration 100: 0.878308892250061\n",
      "Loss at iteration 200: 0.754825234413147\n",
      "Loss at iteration 300: 0.6911817789077759\n",
      "Loss at iteration 400: 0.650195837020874\n",
      "Loss at iteration 500: 0.6206653118133545\n",
      "Loss at iteration 600: 0.5979087352752686\n",
      "Loss at iteration 700: 0.5795814990997314\n",
      "Loss at iteration 800: 0.5643594264984131\n",
      "Loss at iteration 900: 0.5514271259307861\n",
      "Loss at iteration 1000: 0.5402486324310303\n",
      "\n",
      "Final Test Accuracy: 0.7764705882352941\n"
     ]
    }
   ],
   "source": [
    "n_iterations = 1000\n",
    "for i in range(1, n_iterations + 1):\n",
    "    Z = model(X_train)  \n",
    "    loss = loss_function(Z, y_train)  \n",
    "    optimizer.zero_grad() \n",
    "    loss.backward()\n",
    "    optimizer.step() \n",
    "    \n",
    "    if i == 1 or i % 100 == 0:\n",
    "        print(f\"Loss at iteration {i}: {loss}\")\n",
    "\n",
    "test_predictions = torch.argmax(\n",
    "    torch.softmax(model(X_test), 1), axis=1  # 6\n",
    ")\n",
    "test_accuracy = float(sum(test_predictions == y_test)) / y_test.shape[0]\n",
    "print(f\"\\nFinal Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f991a71-3d31-43ce-aa2f-b1b0d4c3e52b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7764705882352941\n",
      "Precision: 0.7744583847525024\n",
      "Recall: 0.7764705882352941\n",
      "F-score: 0.775284264857157\n"
     ]
    }
   ],
   "source": [
    "evaluation(y_test, test_predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
